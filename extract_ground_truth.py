# This file accepts voila tsv inputs, an transcript DB generated by run_validations.py and creates a voila tsv with
# PSI quantifications based on the ground truth.

import argparse
import numpy as np
import gffutils
import os
from tools.majiq import Majiq
import pickle

hash_map = [{}, {}]

__author__    = "Jorge D. Vaquero"
__copyright__ = "Licensed under GNU GPLv3"


class Variation(object):

    def __init__(self, gene_id, transcript, start, end, ratio):
        self.gene = gene_id
        self.transcript_list = [transcript]
        self.ratio = np.copy(ratio)
        self.start = start
        self.end = end

    def update(self, ratio):
        self.ratio += ratio

    def add_transcript(self, transcript):
        self.transcript_list.append(transcript)

def new_variation(gene_id, transcript, start, end, isexon, ratio, ir=False):
    prim_key = '%s:%s-%s' % (gene_id, start, end)
    if ir:
        prim_key = 'IR:' + prim_key
    indx = 0 if isexon else 1
    try:
        obj = hash_map[indx][prim_key]
        obj.update(ratio)
        obj.add_transcript(transcript)
    except KeyError:
        obj = Variation(gene_id, transcript, start, end, ratio)
        hash_map[indx][prim_key] = obj

    return obj

overlap_g = {}
def parse_annotation_db(fn, dbfld, ratios):
    db = gffutils.create_db(fn, dbfn='%s/db.tmp' % dbfld, force=True)
    for ii in db.features_of_type('gene'):
        gnid = ii.attributes['ID'][0]
        for txt in db.children(ii, level=1):
            txtid = txt.attributes['ID'][0]
            jstart = -1
            try:
                rat = ratios[txtid]
            except KeyError:
                rat = 0.
            for ex in db.children(txt, level=1, featuretype='exon', order_by='start'):
                #print gnid, txtid, ex.start, ex.end

                new_variation(gnid, txtid, ex.start, ex.end, isexon=True, ratio=rat)

                if jstart == -1:
                    jstart = ex.end
                    continue
                jend = ex.start
                new_variation(gnid, txtid, jstart, jend, isexon=False, ratio=rat)
                jstart = ex.end


def parse_transcript_file(fname, ttable):
    tlb = {}
    gene_tlb = {}
    transcript_length = {}

    with open(ttable) as fp:
        for ll in fp.readlines()[1:]:
            if ll.startswith('#'):
                continue

            tab = ll.strip().split()
            tlb[tab[0]] = tab[1]
            gene_tlb[tab[1]] = tab[2]
            transcript_length[tab[1]] = int(tab[3])

    ncol = -1

    transcript_count = {}
    gene_total = {}
    with open(fname) as fp:
        for ll in fp.readlines()[1:]:
            if ll.startswith('#ID'):
                tab = ll.strip().split()
                cond = tab[1]
                continue

            if ll.startswith('#'):
                continue

            tab = ll.strip().split()
            try:
                trans = tlb[tab[0]]
            except KeyError:
                print('Not exist transcript %s', tab[0])

            values = float(tab[1])
            values /= transcript_length[trans]
            transcript_count[trans] = values
            gn = gene_tlb[trans]
            try:
                gene_total[gn] += values
            except KeyError:
                gene_total[gn] = values

    return transcript_count


def main(input, ttfile, ttable, outDir, sam_id, dbfile, pre_db=False):
    global hash_map
    if not pre_db:
        ratios_dict = parse_transcript_file(ttfile, ttable)
        tmpdir = '%s/tmp' % outDir
        if not os.path.exists(tmpdir):
            os.makedirs(tmpdir)
        # dbfile = '%s/db' % outDir
        parse_annotation_db(fn=dbfile, dbfld=tmpdir, ratios=ratios_dict)
        with open("%s/annot.pkl" % outDir, 'w+b') as fp:
            pickle.dump(hash_map, fp)
    else:
        fp = open("%s/annot.pkl" % outDir, 'rb')
        hash_map = pickle.load(fp)
        fp.close()

    Majiq.translate_quantifications(input, hash_map, outfile='%s/%s.tsv' % (outDir, sam_id))


if __name__ == '__main__':
    parser = argparse.ArgumentParser()

    parser.add_argument('-o', '--output', action='store', dest='outDir', default='./',
                        help='Output directory where the output files will be stored')

    parser.add_argument('truth_file', type=str, help='Pickle file created by gen_truth pipeline.')
    parser.add_argument('input', type=str,  action='store')
    parser.add_argument('ttable',  type=str, action='store')
    parser.add_argument('sample_id', type=str, action='store')
    parser.add_argument('db', action='store')
    parser.add_argument('--reuse_db', action='store_true')


    args = parser.parse_args()
    print( args)
    main(args.input, args.truth_file, args.ttable, args.outDir, args.sample_id, args.db, args.reuse_db)
